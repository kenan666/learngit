# 数据处理
## TFRecored输入数据格式
*   TFRecored文件通过  tf.train.Example Protocol  Buffer 的格式存储
* 图像处理函数 ，具体通过  图像编码处理、图像大小调整、图像翻转、图像色彩调整、处理标注框等函数方法实现图像预处理。方法的实现可以调用API，实现图像预处理。其中图像大小调整算法包括 1-双线性插值法，2-最邻近算法，3-双三次插值法，4-面积插值法

## 多线程输入数据处理框架
* 经典的输入数据处理流程：指定原始数据的文件列表-》创建文件列表队列-》从文件中读取数据-》数据预处理-》整理成Batch作为神经网络输入
* 利用队列与多线程框架进行输入数据的预处理

## 数据集
* 每一个数据来源被抽象成一个“数据集”，以数据集为基本对象，方便进行 batching，随机打乱（shuffle）操作。tf.contrib.data  ->tf.data
* 数据集读取数据的基本步骤：1-定义数据集的构造方法-》2-定义遍历器-》3-使用get_next()方法从遍历器中读取数据张量，作为计算图其他部分的输入
**注意点**
* 1、自然语言处理中，训练数据通常是以每一条数据的形式存在文本文件中，此时需要使用TextLineDataset来更方便的读取数据、
* 2、图像相关任务中，输入数据通常以TFRecord形式存储，可以利用TFRecordDataset来读取数据*与文本不同的，每一个TFRecord都有自己不同的feature格式，所以读取TFRecord时，需要提供一个parser函数来解析所读取的TFRecord的数据格式*

### 数据集的高级操作
**数据集框架提供的一些方便实用的API**
* map  通过map方法实现TFRecord 解析
```
dataset = dataset.map(parser)
```
* map(parser)表示对数据集中的每一条数据调用参数中指定的parser方法，对数据进行处理之后，map将处理后的数据包装成一个新的数据集返回。**map函数比较灵活，可以适用于任何数据预处理操作**
```
distorted_image = preprocess_for_train(decode_image,image_size,image_size,None)    ------> 等价于
dataset = dataset.map(lambda x :preprocess_for_train(x,image_size,image_size,None))
```
* tf.train.batch   tf.train.shuffle_batch  在数据集实现方法
```
dataset = dataset.shuffle(buffer_size)   -->随机打乱顺序
dataset = dataset.batch(batch_size)  -->将数据组合成batch
```
* repeat  也是常用的数据集操作  --》将数据集中的数据复制多份，其中一份称为epoch
```
dataset = dataset.repeat(N)  -->将数据集复制多份
```
*如果数据集在repeat之前已经进行了shuffle操作，输出的每个epoch中随机shuffle的结果不一定相同*

###
* 1

* 2 今天我*学* 习了**git**
```html
<body>
    好好撸代码  ，天天向上  。。。 ，真香
</body>
```
