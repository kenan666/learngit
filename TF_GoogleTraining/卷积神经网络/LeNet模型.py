'''
LeNet模型总共为7层，分别为：
卷积层-》池化层-》卷积层-》池化层-》全连接层-》全连接层-》全连接层

1、卷积层
输入矩阵大小 ： 32*32*1 、卷积尺寸大小 5*5 ，深度为  6 、  不使用全 0 填充 ，步长为  1

2、池化层
这一层的输入是上一层的输出，矩阵大小  28*28*6；本层过滤器大小 2*2 ，步长为 2 ；输出矩阵大小 ：14*14*6

3、卷积层
输入矩阵大小 14*14*6 ；使用过滤器大小：5*5，深度为 16 ；步长为 1 ； 输出为  10*10*16

4、池化层
输入矩阵大小：10*10*16 ；过滤器大小 ：2*2  ，步长为 2；  输出矩阵大小 ：5*5*16

5、全连接层
输入矩阵大小 ： 5*5*16 ；---》本层输出节点 120个。--》总结点数  5*5*16*120+120=48120 个

6、全连接层
本层输入节点 120个，输出节点84个，总数为  120*84+84 = 10164

7、全连接层
本层输入节点 84 ，输出节点 10 ，总数  -》84*10+10 = 850

---------------------------------------
#调整输入数据 placeholder的格式，输入一个四维矩阵：
x = tf.placeholder(tf.float32,[
    BATCH_SIZE,   #  第一维表示batch中样例的个数
    mnist_inference.IMAGE_SIZE,   #第二维和第三维表示图片的尺寸
    mnist_inference.IMAGE_SIZE,
    mnist_inference.NUM_CHANNEL],   #  第四维表示图片的深度，对于RGB来说，深度为3
    name = 'x-input')

#  类似的将输入的训练数据格式调整为一个四维矩阵，并将这个调整后的数据传入 sess.run()。
reshape_xs = np.reshape(xs,(BATCH_SIZE,
                        mnist_inference.IMAGE_SIZE,
                        mnist_inference.IMAGE_SIZE,
                        mnist_inference.NUM_CHANNEL))
----------------------------------------
'''